{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet TAL M1 S1 : POS Tagging\n",
    "structure du projet expliqué ici : https://u-paris.zoom.us/rec/share/rFB-gp7vkgMK31kfPxEsyNF2k6q7mHcq3P9MQiovimkr9ebIewZpuD62RBk6SmM.31Mmzx1VyMqQXRtu?startTime=1607605609000"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Implémentation du classifieur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import du corpus\n",
    "Cours Zoom du 17/12 - 35 min\n",
    "\n",
    "On charge les trois corpus *in-domain* sous la forme de listes de listes de dictionnaires : chaque phrase est une liste de dictionnaire avec une clef : le mot, associée à son POS tag. \n",
    "\n",
    "On utilise les trois corpus distincts de French-GSD :\n",
    "- Train : apprentissage.\n",
    "- Dev : validation. Pour tester et améliorer le modèle. \n",
    "- Test : évaluation. On ne l'utilisera pas pendant l'apprentissage ou le test."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_corpus(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read() # chargement du corpus\n",
    "    content = content.split(\"\\n\\n\") # séparation en phrases\n",
    "    corpus = []\n",
    "    for phrase in content: # pour chaque phrase\n",
    "        phrase_list = [] # liste qui contiendra 1 dictionnaire par mot de la phrase\n",
    "        for line in phrase.splitlines():\n",
    "            dico_mot = {} # dictionnaire qui contiendra les features d'un mot (mot, lemme, pos)\n",
    "            if not line.startswith(\"#\"): # on ignore les lignes qui commencent par #\n",
    "                features = line.split(\"\\t\")\n",
    "                dico_mot[\"mot\"] = features[1] ####### \n",
    "                dico_mot[\"POS\"] = features[3]\n",
    "                phrase_list.append(dico_mot)\n",
    "        corpus.append(phrase_list)\n",
    "    return corpus\n",
    "\n",
    "gsd_train = load_corpus(\"corpus-in-domain/fr_gsd-ud-train.conllu\")\n",
    "gsd_test = load_corpus(\"corpus-in-domain/fr_gsd-ud-test.conllu\")\n",
    "gsd_dev = load_corpus(\"corpus-in-domain/fr_gsd-ud-dev.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---- Aperçus d'une phrase de chaque corpus-----\n\n[{'mot': \"L'\", 'POS': 'DET'}, {'mot': 'œuvre', 'POS': 'NOUN'}, {'mot': 'est', 'POS': 'AUX'}, {'mot': 'située', 'POS': 'VERB'}, {'mot': 'dans', 'POS': 'ADP'}, {'mot': 'la', 'POS': 'DET'}, {'mot': 'galerie', 'POS': 'NOUN'}, {'mot': 'des', 'POS': '_'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'les', 'POS': 'DET'}, {'mot': 'batailles', 'POS': 'NOUN'}, {'mot': ',', 'POS': 'PUNCT'}, {'mot': 'dans', 'POS': 'ADP'}, {'mot': 'le', 'POS': 'DET'}, {'mot': 'château', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'Versailles', 'POS': 'PROPN'}, {'mot': '.', 'POS': 'PUNCT'}]\n\n[{'mot': 'Ce', 'POS': 'DET'}, {'mot': 'résultat', 'POS': 'NOUN'}, {'mot': 'provient', 'POS': 'VERB'}, {'mot': 'à', 'POS': 'ADP'}, {'mot': 'hauteur', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': '18,5', 'POS': 'NUM'}, {'mot': 'ME', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'la', 'POS': 'DET'}, {'mot': 'progression', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'la', 'POS': 'DET'}, {'mot': 'rentabilité', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': \"l'\", 'POS': 'DET'}, {'mot': 'habitat', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'loisirs', 'POS': 'NOUN'}, {'mot': 'qui', 'POS': 'PRON'}, {'mot': 'dégage', 'POS': 'VERB'}, {'mot': 'une', 'POS': 'DET'}, {'mot': 'marge', 'POS': 'NOUN'}, {'mot': 'opérationnelle', 'POS': 'ADJ'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': '9,5', 'POS': 'NUM'}, {'mot': '%', 'POS': 'SYM'}, {'mot': 'contre', 'POS': 'ADP'}, {'mot': '8,5', 'POS': 'NUM'}, {'mot': '%', 'POS': 'SYM'}, {'mot': \"l'\", 'POS': 'DET'}, {'mot': 'année', 'POS': 'NOUN'}, {'mot': 'passée', 'POS': 'ADJ'}, {'mot': '.', 'POS': 'PUNCT'}]\n\n[{'mot': 'Cette', 'POS': 'DET'}, {'mot': 'espèce', 'POS': 'NOUN'}, {'mot': 'est', 'POS': 'AUX'}, {'mot': 'endémique', 'POS': 'ADJ'}, {'mot': 'du', 'POS': '_'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'le', 'POS': 'DET'}, {'mot': 'département', 'POS': 'NOUN'}, {'mot': 'de', 'POS': 'ADP'}, {'mot': 'Nariño', 'POS': 'PROPN'}, {'mot': 'en', 'POS': 'ADP'}, {'mot': 'Colombie', 'POS': 'PROPN'}, {'mot': '.', 'POS': 'PUNCT'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Aperçus d'une phrase de chaque corpus-----\", end=\"\\n\\n\")\n",
    "print(gsd_train[1], end=\"\\n\\n\")\n",
    "print(gsd_test[100], end=\"\\n\\n\")\n",
    "print(gsd_dev[564])"
   ]
  },
  {
   "source": [
    "## Extraction des caractéristiques\n",
    "Pour clarifier le pipeline, nous allons construire de nouveaux dictionnaires qui contiennent pour chaque mot toutes les caractéristiques que nous allons utiliser dans le perceptron :\n",
    "- mot\n",
    "- mot précédent\n",
    "- mot suivant\n",
    "- commence par une lettre majuscule\n",
    "- est numérique\n",
    "- contient des caractères non alphanumériques"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'mot': 'Ismene', 'POS': 'PROPN', 'préc': 'START', 'suiv': 'entre', 'maj': True, 'nb': False, 'non alphanum': False}\n{'mot': 'entre', 'POS': 'VERB', 'préc': 'Ismene', 'suiv': 'et', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'et', 'POS': 'CCONJ', 'préc': 'entre', 'suiv': 'annonce', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'annonce', 'POS': 'VERB', 'préc': 'et', 'suiv': 'que', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'que', 'POS': 'SCONJ', 'préc': 'annonce', 'suiv': \"c'\", 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': \"c'\", 'POS': 'PRON', 'préc': 'que', 'suiv': 'est', 'maj': False, 'nb': False, 'non alphanum': True}\n{'mot': 'est', 'POS': 'AUX', 'préc': \"c'\", 'suiv': 'Farnace', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'Farnace', 'POS': 'PROPN', 'préc': 'est', 'suiv': 'qui', 'maj': True, 'nb': False, 'non alphanum': False}\n{'mot': 'qui', 'POS': 'PRON', 'préc': 'Farnace', 'suiv': 'a', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'a', 'POS': 'AUX', 'préc': 'qui', 'suiv': 'mis', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'mis', 'POS': 'VERB', 'préc': 'a', 'suiv': 'le', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'le', 'POS': 'DET', 'préc': 'mis', 'suiv': 'feu', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'feu', 'POS': 'NOUN', 'préc': 'le', 'suiv': 'à', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'à', 'POS': 'ADP', 'préc': 'feu', 'suiv': 'la', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'la', 'POS': 'DET', 'préc': 'à', 'suiv': 'flotte', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'flotte', 'POS': 'NOUN', 'préc': 'la', 'suiv': 'romaine', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': 'romaine', 'POS': 'ADJ', 'préc': 'flotte', 'suiv': '.', 'maj': False, 'nb': False, 'non alphanum': False}\n{'mot': '.', 'POS': 'PUNCT', 'préc': 'romaine', 'suiv': 'END', 'maj': False, 'nb': False, 'non alphanum': True}\n"
     ]
    }
   ],
   "source": [
    "def feature_extraction(corpus):\n",
    "    \n",
    "    # clés des dictionnaires\n",
    "    mot = \"mot\"\n",
    "    pos = \"POS\"\n",
    "    mot_prec = \"préc\"\n",
    "    mot_suiv = \"suiv\"\n",
    "    maj = \"maj\"\n",
    "    num = \"nb\"\n",
    "    nonAlphanum = \"non alphanum\"\n",
    "\n",
    "    corpus_features = corpus.copy() # copie de la liste pour ne pas modifier la liste d'origine\n",
    "\n",
    "    for phrase in corpus_features: # ajout des features additionnelles\n",
    "        for prev, word, suiv in zip([{mot : \"START\"}] + phrase[:-1], phrase, phrase[1:] + [{mot : \"END\"}]): # on crée des triplets de mot précédent, mot, mot suivant\n",
    "            # avec \"START\" en prev pour le 1er mot\n",
    "            # et \"END\" en suiv pour le dernier\n",
    "            word.update({\n",
    "                mot_prec : prev[mot],\n",
    "                mot_suiv : suiv[mot],\n",
    "                maj : word[mot].istitle(),\n",
    "                num : word[mot].isnumeric(),\n",
    "                nonAlphanum : not word[mot].isalnum()})\n",
    "\n",
    "    return corpus_features\n",
    "\n",
    "gsd_train_features = feature_extraction(gsd_train)\n",
    "print(*gsd_train_features[4], sep=\"\\n\")"
   ]
  },
  {
   "source": [
    "## Implémentation de l'algorithme de classification\n",
    "Il faut choisir une régression logistique ou un perceptron moyenné. > plutôt perceptron (explication dans zoom 17/12)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evaluation des performances sur le corpus de validation (Dev)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evaluation sur le corpus Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation hors-domaine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Analyse de l'impact du changement de domaine\n",
    "* identifier causes de la baisse de performance : analyse de sortie, matrice de confusion, erreurs les + fréquentes\n",
    "* réfléchir à des caractéristiques plus adaptées\n",
    "* sélection d'un nouvel ensemble d'apprentissage avec des exemples représentatif (généré par un modèle de langue type TP2)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Corpus UGC (User-generated content)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Corpus littéraire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Développement de systèmes robutes au changement de domaine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}