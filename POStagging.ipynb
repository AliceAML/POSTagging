{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet TAL M1 S1 : POS Tagging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Implémentation du classifieur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import du corpus\n",
    "Cours Zoom du 17/12 - 35 min\n",
    "\n",
    "On charge les trois corpus *in-domain* sous la forme de listes de listes de dictionnaires : chaque phrase est une liste de dictionnaire avec une clef : le mot, associée à son POS tag."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_corpus(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read() # chargement du corpus\n",
    "    content = content.split(\"\\n\\n\") # séparation en phrases\n",
    "    corpus = []\n",
    "    for phrase in content: # pour chaque phrase\n",
    "        phrase_list = [] # liste qui contiendra 1 dictionnaire par mot de la phrase\n",
    "        for line in phrase.splitlines():\n",
    "            dico_mot = {} # dictionnaire qui contiendra les features d'un mot (mot, lemme, pos)\n",
    "            if not line.startswith(\"#\"): # on ignore les lignes qui commencent par #\n",
    "                features = line.split(\"\\t\")\n",
    "                dico_mot[features[1]] = features[3]\n",
    "                phrase_list.append(dico_mot)\n",
    "        corpus.append(phrase_list)\n",
    "    return corpus\n",
    "\n",
    "gsd_train = load_corpus(\"corpus-in-domain/fr_gsd-ud-train.conllu\")\n",
    "gsd_test = load_corpus(\"corpus-in-domain/fr_gsd-ud-test.conllu\")\n",
    "gsd_dev = load_corpus(\"corpus-in-domain/fr_gsd-ud-dev.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---- Aperçus d'une phrase de chaque corpus-----\n\n[{\"L'\": 'DET'}, {'œuvre': 'NOUN'}, {'est': 'AUX'}, {'située': 'VERB'}, {'dans': 'ADP'}, {'la': 'DET'}, {'galerie': 'NOUN'}, {'des': '_'}, {'de': 'ADP'}, {'les': 'DET'}, {'batailles': 'NOUN'}, {',': 'PUNCT'}, {'dans': 'ADP'}, {'le': 'DET'}, {'château': 'NOUN'}, {'de': 'ADP'}, {'Versailles': 'PROPN'}, {'.': 'PUNCT'}]\n\n[{'Ce': 'DET'}, {'résultat': 'NOUN'}, {'provient': 'VERB'}, {'à': 'ADP'}, {'hauteur': 'NOUN'}, {'de': 'ADP'}, {'18,5': 'NUM'}, {'ME': 'NOUN'}, {'de': 'ADP'}, {'la': 'DET'}, {'progression': 'NOUN'}, {'de': 'ADP'}, {'la': 'DET'}, {'rentabilité': 'NOUN'}, {'de': 'ADP'}, {\"l'\": 'DET'}, {'habitat': 'NOUN'}, {'de': 'ADP'}, {'loisirs': 'NOUN'}, {'qui': 'PRON'}, {'dégage': 'VERB'}, {'une': 'DET'}, {'marge': 'NOUN'}, {'opérationnelle': 'ADJ'}, {'de': 'ADP'}, {'9,5': 'NUM'}, {'%': 'SYM'}, {'contre': 'ADP'}, {'8,5': 'NUM'}, {'%': 'SYM'}, {\"l'\": 'DET'}, {'année': 'NOUN'}, {'passée': 'ADJ'}, {'.': 'PUNCT'}]\n\n[{'Cette': 'DET'}, {'espèce': 'NOUN'}, {'est': 'AUX'}, {'endémique': 'ADJ'}, {'du': '_'}, {'de': 'ADP'}, {'le': 'DET'}, {'département': 'NOUN'}, {'de': 'ADP'}, {'Nariño': 'PROPN'}, {'en': 'ADP'}, {'Colombie': 'PROPN'}, {'.': 'PUNCT'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Aperçus d'une phrase de chaque corpus-----\", end=\"\\n\\n\")\n",
    "print(gsd_train[1], end=\"\\n\\n\")\n",
    "print(gsd_test[100], end=\"\\n\\n\")\n",
    "print(gsd_dev[564])"
   ]
  },
  {
   "source": [
    "## Séparation des corpus d'apprentissage et de validation\n",
    "Cours Zoom du 17/12 - début\n",
    "\n",
    "Cours Zoom du 19/12 ?\n",
    "\n",
    "Déjà fait puisqu'on a 3 fichiers différents il me semble."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Implémentation de l'algorithme de classification\n",
    "Il faut choisir une régression logistique ou un perceptron moyenné."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evaluation des performances sur le corpus de validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation hors-domaine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Analyse de l'impact du changement de domaine\n",
    "* identifier causes de la baisse de performance : analyse de sortie, matrice de confusion, erreurs les + fréquentes\n",
    "* réfléchir à des caractéristiques plus adaptées\n",
    "* sélection d'un nouvel ensemble d'apprentissage avec des exemples représentatif (généré par un modèle de langue type TP2)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Corpus UGC (User-generated content)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Corpus littéraire"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Développement de systèmes robutes au changement de domaine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}